[server]
grpc_addr = "0.0.0.0:50051"
try_max_time = 3

[remote_server]
endpoints = ["http://0.0.0.0:50051"]
timeout = 5000  # milliseconds

[voice_chat]
model_path= "https://api.siliconflow.cn/v1/audio/transcriptions"
api_key = ""
model_name = "FunAudioLLM/SenseVoiceSmall"

[chat_model]
knowledge_base = ""

[[chat_model.remote_models]]
enabled = true
priority = 3
model_path = "https://api.siliconflow.cn/v1/chat/completions"
model_name = "Qwen/Qwen2.5-7B-Instruct"
api_key= ""
stream = true
parameters = { temperature = "0.7", max_tokens = "2048" }

[[chat_model.local_models]]
enabled = true
priority = 1
wasm_path = "/path/to/wasme-ggml.wasm"
model_path = "/path/to/model.gguf"
n_gpu_layers = 0
ctx_size = 1024
instance_count = 1
model_type = "qwen"  # or "deepseek"
stream = true

[chat_voice]
model_path= ""
